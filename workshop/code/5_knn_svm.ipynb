{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "<br> 1. Load IRIS dataset. It contains 50 samples of the iris flower varieties. Each row contains four features (length and width of sepals and petals in cm).\n",
    "<br> 2. Build a classification model that takes four features as input and predict the species of IRIS flower (setosa/virginica/versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import IRIS dataset\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# divide this data into features and labels\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "print(f\"X is of type: {type(X)}\")\n",
    "print(f\"Y is of type: {type(Y)}\")\n",
    "\n",
    "# How does our data look\n",
    "print(f\"First 5 rows of our data: {X[:5, :]}\")\n",
    "print(f\"Unique labels: {np.unique(Y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's split our data into 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% testing sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Xtrain: {Xtrain.shape}\")\n",
    "print(f\"Xtrain: {Ytrain.shape}\")\n",
    "print(f\"Xtrain: {Xtest.shape}\")\n",
    "print(f\"Xtrain: {Ytest.shape}\")\n",
    "\n",
    "print(f\"First 5 rows of Xtrain: {Xtrain[:5, :]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build classification model, train, test and measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Build a KNN using 5 neighbor nodes\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model using our training data\n",
    "knn_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Training accuracy\n",
    "knn_acc = metrics.accuracy_score(Ytrain, knn_model.predict(Xtrain))\n",
    "print(f\"KNN training accuracy: {knn_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform testing and measure test accuracy.\n",
    "knn_acc_test = metrics.accuracy_score(Ytest, knn_model.predict(Xtest))\n",
    "print(f\"KNN test accuracy: {knn_acc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Support Vector Machine\n",
    "<br> Same as before -\n",
    "<br> 1. Import libraries and dataset\n",
    "<br> 2. Train-test split\n",
    "<br> 3. Extend previous code by building a SVM classification model for this data using a linear kerne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a linear kernel with the default parameters.\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Fit an SVM using linear kernel\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Training/Testing accuracy\n",
    "svm_acc = metrics.accuracy_score(Ytrain, svm_model.predict(Xtrain))\n",
    "print(f\"SVM training accuracy: {svm_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector data points can be found using support_vectors parameter of svm model.\n",
    "\n",
    "print(\"Support vector type:\", type(svm_model.support_vectors_))\n",
    "print(f\"Support vector shape: {svm_model.support_vectors_.shape}\")\n",
    "\n",
    "print(f\"Data has a total of {svm_model.support_vectors_.shape[0]} support vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "svm_acc_test = metrics.accuracy_score(Ytest, svm_model.predict(Xtest))\n",
    "\n",
    "print(f\"SVM test accuracy: {svm_acc_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Polynomial kernel\n",
    "<!-- <br> See in presentation, IRIS dataset class 1 and class 2 are not linearly separable.\n",
    "<br> So, we remove out class 0 from X (data) and Y (label).\n",
    "<br> Numpy __in1d()__ function can be used to do that. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with linear kernel first to see accuracy\n",
    "svc_model = svm.SVC(kernel='poly', degree=2, gamma='auto')\n",
    "svc_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Training/testing accuracy\n",
    "svc_acc = metrics.accuracy_score(Ytrain, svc_model.predict(Xtrain))\n",
    "print(f\"SVM-poly training accuracy: {svc_acc}\")\n",
    "\n",
    "svc_acc_test = metrics.accuracy_score(Ytest, svc_model.predict(Xtest))\n",
    "print(f\"SVM-poly testing accuracy: {svc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: RBF kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with linear kernel first to see accuracy\n",
    "svc_model = svm.SVC(kernel='rbf', degree=2, gamma='auto')\n",
    "svc_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Training/testing accuracy\n",
    "svc_acc = metrics.accuracy_score(Ytrain, svc_model.predict(Xtrain))\n",
    "print(f\"SVM-rbf training accuracy: {svc_acc}\")\n",
    "\n",
    "svc_acc_test = metrics.accuracy_score(Ytest, svc_model.predict(Xtest))\n",
    "print(f\"SVM-rbf testing accuracy: {svc_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of C parameter on SVM\n",
    "<br> C is a __regularization parameter__ that controls the trade off between the achieving a low training error and a low testing error that is the ability to generalize your classifier to unseen data.\n",
    "<br> C is a Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n",
    "<br> C is 1 by default.\n",
    "<br> For noisy data, C should have lower value. (less regularize, allowing more support vectors.)\n",
    "<br> High C value corresponds to high penalty for mis-classification, thus, learnt margin will be narrow, resulting in small number of support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher C value.\n",
    "\n",
    "svc_model = svm.SVC(kernel='linear', C=1e2)\n",
    "svc_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Support vectors\n",
    "print(f\"Data has a total of {svc_model.support_vectors_.shape[0]} support vectors.\")\n",
    "\n",
    "# Training/testing accuracy\n",
    "svc_acc = metrics.accuracy_score(Ytrain, svc_model.predict(Xtrain))\n",
    "print(f\"SVM-rbf training accuracy: {svc_acc}\")\n",
    "\n",
    "svc_acc_test = metrics.accuracy_score(Ytest, svc_model.predict(Xtest))\n",
    "print(f\"SVM-rbf testing accuracy: {svc_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower C value.\n",
    "\n",
    "svc_model = svm.SVC(kernel='linear', C=1e-2)\n",
    "svc_model.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Support vectors\n",
    "print(f\"Data has a total of {svc_model.support_vectors_.shape[0]} support vectors.\")\n",
    "\n",
    "# Training/testing accuracy\n",
    "svc_acc = metrics.accuracy_score(Ytrain, svc_model.predict(Xtrain))\n",
    "print(f\"SVM-rbf training accuracy: {svc_acc}\")\n",
    "\n",
    "svc_acc_test = metrics.accuracy_score(Ytest, svc_model.predict(Xtest))\n",
    "print(f\"SVM-rbf testing accuracy: {svc_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
